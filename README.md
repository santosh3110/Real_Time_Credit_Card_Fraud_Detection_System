# Real-Time Credit Card Fraud Detection System
A real-time machine learning pipeline for detecting fraudulent credit card transactions using CatBoost, Kafka, MongoDB and Streamlit. This system leverages CatBoost classifier to detect fraudulent transactions as they occur. This model simulates streaming transactions using faker library, classifies them on-the-fly, provides an immediate email alert using SMTP PORT and SMTP SERVER, stores them in MongoDB and visualizes fraud patterns on a live dashboard.


[![Python](https://img.shields.io/badge/Python-3.11-blue)](https://www.python.org/)
[![Kafka](https://img.shields.io/badge/Kafka-3.0-orange)](https://kafka.apache.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-6.0-green)](https://www.mongodb.com/)
[![CatBoost](https://img.shields.io/badge/CatBoost-1.7-yellow)](https://catboost.ai/)
[![Streamlit](https://img.shields.io/badge/Streamlit-2.0-blue)](https://streamlit.io/)



ğŸ”— **Live Streamlit App**: [Launch Dashboard](https://realtimecreditcardfrauddetectionsystem-csbhj8exeew6z7xew4g8xo.streamlit.app/)

---

## ğŸ“Œ Table of Contents

- [ğŸ“¸ Demo Screenshots](#-demo-screenshots)
- [ğŸ“ Dataset](#-dataset)
- [ğŸ“¦ Features](#-features)
- [ğŸ§± Project Architecture](#-project-architecture)
- [ğŸš€ Getting Started](#-getting-started)
- [ğŸ“Š Streamlit Dashboard](#-streamlit-dashboard)
- [ğŸ§  Model & Evaluation](#-model--evaluation)
- [ğŸ”„ Streaming Pipeline](#-streaming-pipeline)
- [ğŸ“ Directory Structure](#-directory-structure)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ“œ License](#-license)

---

## ğŸ“¸ Demo Screenshots

> ğŸ”»screenshots:
- Dashboard homepage

![alt text](image-2.png)

- Filter view

![alt text](image-3.png)

- Kafka stream logs

![alt text](image-4.png)

- Fraud and Non Fraud Database stored in MongoDB:

![alt text](image-5.png)

- Sample mail alerts sent:

![alt text](image-6.png)



---

## ğŸ“ Dataset

The dataset used for training and evaluation is sourced from Hugging Face and contains synthetic credit card transaction data. Below are the key details:

    Source: The dataset is obtained from Hugging Face (dazzle-nu/CIS435-CreditCardFraudDetection).

    Features:
        cc_num: Credit card number.
        amt: Transaction amount.
        trans_date_trans_time: Date and time of the transaction.
        dob: Date of birth of the cardholder.
        lat and long: Latitude and longitude of the transaction location.
        merch_lat and merch_long: Latitude and longitude of the merchant location.
        is_fraud: Binary target variable indicating whether the transaction is fraudulent (1 for fraud, 0 for legitimate).

    Preprocessing:
        The dataset undergoes several preprocessing steps, including handling missing values, converting data types, and creating new features such as age, is_large_transaction, and log_amt.
        The trans_date_trans_time and dob are converted to datetime formats.
        The distance_km feature is calculated using the Haversine distance formula to determine the distance between the customer and merchant locations.
        The is_large_transaction feature is created to indicate transactions exceeding a certain amount threshold.
        The log_amt feature is the logarithmic transformation of the transaction amount to handle skewness.

This dataset is well-suited for training a fraud detection model due to its comprehensive feature set and realistic transaction scenarios.

---

## ğŸ“¦ Features

âœ… Real-time transaction simulation using **Faker**  
âœ… Kafka Producer + Consumer for streaming pipeline  
âœ… Feature engineering and transformation logic  
âœ… **CatBoostClassifier** for high-performance fraud detection  
âœ… **SHAP** visualizations for model explainability  
âœ… MongoDB integration for storing flagged transactions  
âœ… Live, interactive dashboard built with **Streamlit**  
âœ… Email alerts for fraudulent activity  
âœ… Fully modular and production-style architecture

---

## ğŸ§± Project Architecture

```text
[Kafka Producer] ---> [Kafka Broker] ---> [Kafka Consumer]
         |                                    |
     [Faker Txn]                         [Feature Transformer]
                                              |
                                       [CatBoost Model]
                                              |
                                 [MongoDB: fraud_alerts / non_fraud]
                                              |
                                      [Streamlit Dashboard + Alerting]
```

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

- Python 3.10+
- Kafka Cluster (e.g., Confluent Cloud or local)
- MongoDB Instance (Cloud or local)

### ğŸ“¥ Clone the Repository

```bash
git clone https://github.com/your-username/Real_Time_Credit_Card_Fraud_Detection_System.git
cd Real_Time_Credit_Card_Fraud_Detection_System
```

### ğŸ“¦ Install Requirements

```bash
pip install -r requirements.txt
```

### ğŸ” Setup `.env`

```env
KAFKA_BOOTSTRAP_SERVERS=your_kafka_server
KAFKA_USERNAME=your_kafka_username
KAFKA_PASSWORD=your_kafka_password
MONGO_URI=your_mongodb_connection_string
SMTP_SERVER=smtp.yourmail.com
SMTP_PORT=587
EMAIL_SENDER=your_email@example.com
EMAIL_PASSWORD=your_email_password
EMAIL_RECEIVER=receiver_email@example.com
```

---

## ğŸ“Š Streamlit Dashboard

Launch the dashboard to view fraud patterns in real-time:

```bash
streamlit run app.py
```

Or open directly:
ğŸ‘‰ [realtimecreditcardfrauddetectionsystem.streamlit.app](https://realtimecreditcardfrauddetectionsystem-csbhj8exeew6z7xew4g8xo.streamlit.app/)

---

## ğŸ”„Training Pipeline

Run the training pipeline:

```bash
python fraud_detection/pipeline/training_pipeline.py
```
or

```bash
python main.py
```

This will execute the following steps:

Ingest data
Validate data
Engineer features
Train the model
Evaluate the model

---

## ğŸ§  Model & Evaluation

- Model: `CatBoostClassifier`
- Evaluation Metrics:
  - **Accuracy**: 99.94%
  - **ROC AUC**: 99.94%
  - **Log Loss**: 0.0020

- SHAP-based interpretability with feature importance ranking

![alt text](image.png)

- Geographical heatmap of fraud transactions by location generated using folium maps

![alt text](image-1.png)


ğŸ“‚ Outputs:
- `trained_model.cbm`
- `evaluation_metrics.csv`
- `shap_values.pkl`

---

## ğŸ”„ Streaming Pipeline

Run the full pipeline:

```bash
python fraud_detection/pipeline/streaming_pipeline.py
```

This runs:
- `kafka_producer` â†’ Sends transactions
- `kafka_consumer` â†’ Classifies and stores transactions
- `alerting` â†’ Sends email for frauds

---

## ğŸ“ Directory Structure

```bash
.
â”œâ”€â”€ app.py                      # Streamlit-based dashboard
â”œâ”€â”€ artifacts/                 # Project artifacts
â”‚   â”œâ”€â”€ dataset/               # Raw and processed datasets
â”‚   â”œâ”€â”€ engineered_data/        # Feature-engineered data
â”‚   â””â”€â”€ reports/                # Evaluation reports and SHAP values
â”œâ”€â”€ build/                      # Build directory
â”œâ”€â”€ catboost_info/               # CatBoost training information
â”œâ”€â”€ config/                     # Configuration files
â”œâ”€â”€ dist/                       # Distribution package
â”œâ”€â”€ fraud_detection/             # Core project package
â”‚   â”œâ”€â”€ components/             # Pipeline components
â”‚   â”‚   â”œâ”€â”€ stage_00_data_ingestion.py  # Data ingestion
â”‚   â”‚   â”œâ”€â”€ stage_01_data_validation.py # Data validation
â”‚   â”‚   â”œâ”€â”€ stage_02_feature_engineering.py # Feature engineering
â”‚   â”‚   â”œâ”€â”€ stage_03_model_training.py    # Model training
â”‚   â”‚   â””â”€â”€ stage_04_model_evaluation.py # Model evaluation
â”‚   â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ constant/               # Project constants
â”‚   â”œâ”€â”€ data_generator/         # Data generation utilities
â”‚   â”œâ”€â”€ entity/                 # Entity classes
â”‚   â”œâ”€â”€ exception/               # Custom exceptions
â”‚   â”œâ”€â”€ logger/                  # Logging utilities
â”‚   â”œâ”€â”€ pipeline/               # Training and streaming pipelines
â”‚   â”œâ”€â”€ streaming/              # Streaming components
â”‚   â””â”€â”€ utils/                 # Utility functions
â”œâ”€â”€ logs/                       # Log files
â”œâ”€â”€ main.py                     # Main execution file
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ research/                    # Research and experimentation
â”œâ”€â”€ saved_models/               # Trained models
â”œâ”€â”€ schema.yaml                 # Data schema
â”œâ”€â”€ setup.py                    # Setup file
â””â”€â”€ template.py                  # Template file\

```

---

## ğŸ› ï¸ Tech Stack

| Component       | Tool/Library                    |
|----------------|----------------------------------|
| ML Model       | CatBoost                        |
| Stream         | Kafka + Confluent               |
| Data Sim       | Faker                            |
| Dashboard      | Streamlit + Plotly              |
| Storage        | MongoDB                         |
| Geo Analysis   | Geopy                            |
| Email Alerts   | SMTP                             |
| Explainability | SHAP                             |
| Packaging      | YAML, Python-dotenv             |

---

## ğŸ“œ License

This project is licensed under the Apache 2.0 License.  
Feel free to use, contribute, or fork!

---

## ğŸ™Œ Acknowledgements

- Thanks to **CatBoost** for blazing-fast tree boosting
- Thanks to **Streamlit** for effortless dashboards
- Inspired by real-world streaming data and fraud challenges

---

## ğŸ“¬ Contact

Santosh Kumar Guntupalli
[GitHub](https://github.com/santosh3110) | [LinkedIn](https://www.linkedin.com/in/santosh-guntupalli-05b285250/)
